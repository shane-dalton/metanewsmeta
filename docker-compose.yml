version: '3'

services:
  metanews:
    build: .
    command: python3 manage.py runserver 0.0.0.0:8000
    image: metanews
    env_file:
      - .env
    volumes:
      - .:/code
    ports:
      - "8003:8000"

#  redis:
#    container_name: metanews-redis
#    image: redis:latest
#    ports:
#      - "6379:6379"
#    depends_on:
#      - metanews

#  flower:
#    image: *metanews
#    container_name: metanews-flower
#    command: flower --broker=redis://redis:6379/0 --port=5555
#    #-A ppg_ngs #{A flag requires .py files, --broker does not port is for webui}
#    volumes:
#      - .:/code
#    restart: on-failure
#    env_file:
#      - ${CONTAINER_ENV_FILE}
#    depends_on:
#      - metanews-redis
#      - metanews
#    ports:
#      - "5555:5555"

  # When running in debug mode with django, celery WILL cause memory leaks
  # due to accumulate data structures that don't get garbage collected
  # python -m celery.bin.celeryd --config=settings
  # https://stackoverflow.com/questions/8426949/django-celery-warnings-about-settings-debug
#  celery0:
#    image: *metanews
#    container_name: metanews-celery-worker-0
#    # This concurrency will need to be tuned according to the available resources on the host server, as
#    # changes in network latency will alter cpu usage and could cause OS cpu/memory "OOM killer" to terminate the process
#    # During testing 5 cores  and 6gb of ram were allocated. If these limits are not met, it may cause instability and/or
#    # Docker sigkill to the processing worker which will cause the run to fail and be reflected in the assay run
#    # review page
#    command: celery -A metanews worker --loglevel=debug -n celery0@%%h -Ofair --concurrency=15
#    volumes:
#      - .:/code
#    restart: on-failure
#    env_file:
#      - .env
#    depends_on:
#      - metanews-redis
#      - metanews
